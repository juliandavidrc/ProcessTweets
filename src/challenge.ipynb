{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in /Users/julianromero/.local/share/virtualenvs/ProcessTweets-raqGfvtZ/lib/python3.11/site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in /Users/julianromero/.local/share/virtualenvs/ProcessTweets-raqGfvtZ/lib/python3.11/site-packages (from memory_profiler) (5.9.8)\n"
     ]
    }
   ],
   "source": [
    "#! pip install -U memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import zipfile\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting zip to gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../data\n",
    "#unzip -p ../data/farmers-tweets.json.zip | gzip > farmers-tweets.json.gz\n",
    "unzip -p ../data/farmers-protest-tweets-2021-2-4.json.zip | gzip > farmers-protest-tweets-2021-2-4.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading tweets as pyspark object\n",
    "\n",
    "Initially the data is a sample of tweets `./data/farmers-tweets.json`, afterwards we'll load the complete json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** File to use: ../data/farmers-protest-tweets-2021-2-4.json.gz\n"
     ]
    }
   ],
   "source": [
    "namef = '../data/farmers-protest-tweets-2021-2-4'\n",
    "#namef = 'farmers-tweets'\n",
    "\n",
    "file_path = namef+'.json.gz'\n",
    "print(f\"** File to use: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first test is perform the data loading over a RDD sprk object.\n",
    "`%memit` magic cell allow us measure memory.\n",
    "\n",
    "*Note: The spark.read.json is running in the .gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 174.91 MiB, increment: 0.00 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----+\n",
      "|created_at|       username|count|\n",
      "+----------+---------------+-----+\n",
      "|2021-02-19|       Preetm91|  267|\n",
      "|2021-02-18|neetuanjle_nitu|  195|\n",
      "|2021-02-17| RaaJVinderkaur|  185|\n",
      "|2021-02-13|MaanDee08215437|  178|\n",
      "|2021-02-12|RanbirS00614606|  176|\n",
      "|2021-02-21|     Surrypuria|  161|\n",
      "|2021-02-18|  rebelpacifist|  153|\n",
      "|2021-02-19|KaurDosanjh1979|  138|\n",
      "|2021-02-23|     Surrypuria|  135|\n",
      "|2021-02-15|         jot__b|  134|\n",
      "+----------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%memit\n",
    "#Creating SparkSession \n",
    "spark = SparkSession.builder.appName('readJson').getOrCreate()\n",
    "#Read file as pyspark object()   \n",
    "data = spark.read.json(file_path)\n",
    "#transformation and renaming columns steps\n",
    "dfcol = data.withColumn(\"created_at\", data[\"date\"].cast('date'))\\\n",
    "                                .withColumn(\"user_id\", data[\"user.id\"])\\\n",
    "                                .withColumn(\"username\", data[\"user.username\"])\n",
    "\n",
    "df = dfcol.select(col(\"created_at\"), col(\"user_id\"), col(\"username\")).groupBy(\"created_at\", \"username\").count()\n",
    "df.sort(df[\"count\"].desc()).show(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading tweets as pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"../data/farmers-tweets.json\"\n",
    "file_path = '../data/farmers-protest-tweets-2021-2-4.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       created_at         username  count\n",
      "35219  2021-02-19         Preetm91    267\n",
      "33193  2021-02-18  neetuanjle_nitu    195\n",
      "26577  2021-02-17   RaaJVinderkaur    185\n",
      "7536   2021-02-13  MaanDee08215437    178\n",
      "2740   2021-02-12  RanbirS00614606    176\n",
      "42691  2021-02-21       Surrypuria    161\n",
      "33396  2021-02-18    rebelpacifist    153\n",
      "34733  2021-02-19  KaurDosanjh1979    138\n",
      "48696  2021-02-23       Surrypuria    135\n",
      "18540  2021-02-15           jot__b    134\n"
     ]
    }
   ],
   "source": [
    "#Read file with json.loads()   \n",
    "data = [json.loads(line) for line in open(file_path, 'r')]\n",
    "#convert to dataframe\n",
    "df = pd.DataFrame(data)\n",
    "#transformation and renaming columns steps\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"date\"]).dt.strftime('%Y-%m-%d')\n",
    "#lambda functions to create new columns from user tag\n",
    "df['username'] = df['user'].apply(lambda d: d['username'])\n",
    "df['user_id'] = df['user'].apply(lambda d: d['id'])\n",
    "\n",
    "dfres = df.groupby(['created_at','username'])['id'].count().reset_index(name=\"count\").sort_values(\"count\", ascending=False) \n",
    "\n",
    "print(dfres.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track memory consumption with %mprun magic command\n",
    "\n",
    "Spark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----+\n",
      "|created_at|       username|count|\n",
      "+----------+---------------+-----+\n",
      "|2021-02-19|       Preetm91|  267|\n",
      "|2021-02-18|neetuanjle_nitu|  195|\n",
      "|2021-02-17| RaaJVinderkaur|  185|\n",
      "|2021-02-13|MaanDee08215437|  178|\n",
      "|2021-02-12|RanbirS00614606|  176|\n",
      "|2021-02-21|     Surrypuria|  161|\n",
      "|2021-02-18|  rebelpacifist|  153|\n",
      "|2021-02-19|KaurDosanjh1979|  138|\n",
      "|2021-02-23|     Surrypuria|  135|\n",
      "|2021-02-15|         jot__b|  134|\n",
      "+----------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/julianromero/Documents/Bench/ProcessTweets/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     9    123.7 MiB    123.7 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    10                                             \n",
      "    11                                             #Creating SparkSession \n",
      "    12    123.7 MiB      0.0 MiB           1       spark = SparkSession.builder.appName('readJson').getOrCreate()\n",
      "    13                                             #Read file as pyspark object()   \n",
      "    14    123.7 MiB      0.0 MiB           1       data = spark.read.json(file_path)    \n",
      "    15                                             #transformation and renaming columns steps\n",
      "    16    123.7 MiB      0.0 MiB           2       dfcol = data.withColumn(\"created_at\", data[\"date\"].cast('date'))\\\n",
      "    17    123.7 MiB      0.0 MiB           1                                   .withColumn(\"user_id\", data[\"user.id\"])\\\n",
      "    18    123.7 MiB      0.0 MiB           1                                   .withColumn(\"username\", data[\"user.username\"])\n",
      "    19                                         \n",
      "    20    123.7 MiB      0.0 MiB           1       df = dfcol.select(col(\"created_at\"), col(\"user_id\"), col(\"username\")).groupBy(\"created_at\", \"username\").count()\n",
      "    21    123.7 MiB      0.0 MiB           1       df.sort(df[\"count\"].desc()).show(10)    \n",
      "    22    123.7 MiB      0.0 MiB           1       return df"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json.gz\"\n",
    "%mprun -f q1_memory q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       created_at         username  count\n",
      "35219  2021-02-19         Preetm91    267\n",
      "33193  2021-02-18  neetuanjle_nitu    195\n",
      "26577  2021-02-17   RaaJVinderkaur    185\n",
      "7536   2021-02-13  MaanDee08215437    178\n",
      "2740   2021-02-12  RanbirS00614606    176\n",
      "42691  2021-02-21       Surrypuria    161\n",
      "33396  2021-02-18    rebelpacifist    153\n",
      "34733  2021-02-19  KaurDosanjh1979    138\n",
      "48696  2021-02-23       Surrypuria    135\n",
      "18540  2021-02-15           jot__b    134\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/julianromero/Documents/Bench/ProcessTweets/src/q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    10    123.9 MiB    123.9 MiB           1   def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    11                                             \n",
      "    12                                             #Read file with json.loads()   \n",
      "    13   2263.2 MiB -499104.4 MiB      117410       data = [json.loads(line) for line in open(file_path, 'r')]\n",
      "    14                                             #convert to dataframe\n",
      "    15   2349.5 MiB     86.3 MiB           1       df = pd.DataFrame(data)\n",
      "    16                                             #transformation and renaming columns steps\n",
      "    17   2359.0 MiB      9.6 MiB           1       df[\"created_at\"] = pd.to_datetime(df[\"date\"]).dt.strftime('%Y-%m-%d')\n",
      "    18   2359.0 MiB -2460732.0 MiB      234815       df['username'] = df['user'].apply(lambda d: d['username'])\n",
      "    19   2298.9 MiB    -60.2 MiB      234815       df['user_id'] = df['user'].apply(lambda d: d['id'])\n",
      "    20                                         \n",
      "    21   2315.8 MiB     16.9 MiB           1       dfres = df.groupby(['created_at','username'])['id'].count().reset_index(name=\"count\").sort_values(\"count\", ascending=False) \n",
      "    22                                         \n",
      "    23   2317.4 MiB      1.7 MiB           1       print(dfres.head(10))\n",
      "    24   2317.4 MiB      0.0 MiB           1       return dfres"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\"\n",
    "%mprun -f q1_time q1_time(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
